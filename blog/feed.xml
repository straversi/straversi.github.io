<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>steven.codes</title>
    <description>I post here about some of the things I&#39;m working on.
</description>
    <link>http://steven.codes/blog/</link>
    <atom:link href="http://steven.codes/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 01 Nov 2016 10:02:26 -0700</pubDate>
    <lastBuildDate>Tue, 01 Nov 2016 10:02:26 -0700</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>Face Morphing</title>
        <description>&lt;div class=&quot;video&quot;&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/kCoy1KtH1Xk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;A face-morphing music video that I made.&lt;/p&gt;&lt;/div&gt;

&lt;h2 id=&quot;basic-morphs&quot;&gt;Basic Morphs&lt;/h2&gt;

&lt;p&gt;To morph two faces together, one can follow this rough outline:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Identify feature points on both images&lt;/li&gt;
  &lt;li&gt;Create a triangulation from one of the sets of points, and apply it to each image.&lt;/li&gt;
  &lt;li&gt;For timestep t out of N timesteps, take the weighted average of each pair of points from the two images, with weights t/N and (N-t)/N. Recover the triangulation on this new set of points. (This amounts to performing an affine transform on each triangle.)&lt;/li&gt;
  &lt;li&gt;Fill the new transformed pixels using the inverse of the affine transform from step 3 to pluck pixel values from the original images. Cross dissolve them proportionally to the timestep.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Below are examples of the feature points used to morph Mozart and Beethoven. The triangulation on Mozart is the version that ended up being used.&lt;/p&gt;

&lt;figure class=&quot;third full align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/music_gifs/lines_1.png &quot; /&gt;
  &lt;figcaption&gt;Mozart features and triangulation&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third full align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/music_gifs/linegif.gif &quot; /&gt;
  &lt;figcaption&gt;The triangulation remains intact throughout the morph&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third full align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/music_gifs/lines_2.png &quot; /&gt;
  &lt;figcaption&gt;Beethoven features with the same triangulation&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here’s an unmarked version of the morph, and the “halfway” face.&lt;/p&gt;

&lt;figure class=&quot;third align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/music_gifs/mozart.gif &quot; /&gt;
  &lt;figcaption&gt;Full morph&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/music_gifs/frame_22.jpg &quot; /&gt;
  &lt;figcaption&gt;Mozthoven&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I had some fun morphing people, and sometimes things. Here are some examples:&lt;/p&gt;

&lt;figure class=&quot;third align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/obamabush/obamabush.gif &quot; /&gt;
  &lt;figcaption&gt;Obama to Bush&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third align-top full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/carloselon/carloselon.gif &quot; /&gt;
  &lt;figcaption&gt;Flores to Musk&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/campaniles/campaniles.gif &quot; /&gt;
  &lt;figcaption&gt;Campanile to Campanile&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;average-face&quot;&gt;Average Face&lt;/h2&gt;

&lt;p&gt;Here, we play around with a dataset of Danish faces. First, we try to find the “average Danish face”.&lt;/p&gt;

&lt;figure&gt;
  &lt;img class=&quot;third&quot; src=&quot;/blog/assets/posts/face-morphing/danes/01-1m.jpg &quot; /&gt;
  &lt;img class=&quot;third&quot; src=&quot;/blog/assets/posts/face-morphing/danes/05-1m.jpg &quot; /&gt;
  &lt;img class=&quot;third&quot; src=&quot;/blog/assets/posts/face-morphing/danes/15-1f.jpg &quot; /&gt;
  &lt;figcaption&gt;Original Danish faces. I then took the average symmetry of their faces.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img class=&quot;third&quot; src=&quot;/blog/assets/posts/face-morphing/danes/dane_0_averaged.jpg &quot; /&gt;
  &lt;img class=&quot;third&quot; src=&quot;/blog/assets/posts/face-morphing/danes/dane_4_averaged.jpg &quot; /&gt;
  &lt;img class=&quot;third&quot; src=&quot;/blog/assets/posts/face-morphing/danes/dane_14_averaged.jpg &quot; /&gt;
  &lt;figcaption&gt;I morphed each Dane into the average symmetry, then took the average color at each pixel to get the Average Dane.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Each of the original Danes’ faces define “Danish space”, as illustrated below. The average of all of the Danish faces is the “Average Dane”.&lt;/p&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/danes/danish_space.png &quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;My (Steven’s) face also exists in space, somewhere. By morphing my face to the geometry of the average Dane, we can push my face further toward the Danish space.&lt;/p&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/danes/danish_swaps.png &quot; /&gt;
  &lt;figcaption&gt;Steven&#39;s face warped to the average Dane geometry, and the average Dane face warped to Steven&#39;s geometry.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here are the live action morphs illustrated in the above figure.&lt;/p&gt;

&lt;figure class=&quot;third align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/danes/dane_to_steven/1.gif &quot; /&gt;
  &lt;figcaption&gt;Average dane morphed to Steven&#39;s face shape&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third align-top&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/danes/steven_to_dane/1.gif &quot; /&gt;
  &lt;figcaption&gt;Steven morphed to average dane&#39;s face shape&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;caricatures&quot;&gt;Caricatures&lt;/h2&gt;

&lt;p&gt;We can push the concept from the last section even further to create caricatures. What if we morphed Steven’s face &lt;em&gt;past&lt;/em&gt; the average Dane geometry, say, twice as far? That would start to expose how the geometry really compares to Steven’s. We could go the other way too: morphing Steven’s face in the &lt;em&gt;opposite&lt;/em&gt; direction from the average Dane geometry. That process would accentuate the features of Steven that are “not Danish”.&lt;/p&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/face-morphing/danes/danish_vector.png &quot; /&gt;
  &lt;figcaption&gt;Taking Steven&#39;s face past the average Danish geometry, and in the opposite direction.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;◼&lt;/p&gt;
</description>
        <pubDate>Tue, 11 Oct 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/face-morphing/</link>
        <guid isPermaLink="true">http://steven.codes/blog/face-morphing/</guid>
        
        <category>published</category>
        
        
      </item>
    
      <item>
        <title>Gradient Domain Fusion</title>
        <description>&lt;p&gt;This post is a modified version of a site that I submitted for a project in my image manipulation class with &lt;a href=&quot;https://scholar.google.com/citations?user=d97bGd8AAAAJ&quot;&gt;Alexei Efros&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;On this page, I give some quick explanations of some algorithms, but the main focus is to display and compare results. The base technique is called Poisson Blending. Its goal is to blend a &lt;em&gt;source&lt;/em&gt; image into a &lt;em&gt;target&lt;/em&gt; image. It accomplishes this by defining constraints based on the &lt;em&gt;gradients&lt;/em&gt; of the pixels in the result image. These constraints can be grouped to form a least-squares problem, which can be represented in sparse matrices and solved by a library least-squares solver.&lt;/p&gt;

&lt;h2 id=&quot;toy-problem-reconstruction&quot;&gt;Toy Problem: Reconstruction&lt;/h2&gt;

&lt;p&gt;To get used to formulating the pixel constraints as least squares problems in sparse matrices, first I practiced simply reconstructing an image given its gradient constraints and a single pixel intensity value.&lt;/p&gt;

&lt;p&gt;In other words, if we are given a matrix of gradient values between pixels:&lt;/p&gt;

&lt;figure class=&quot;fourth&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/equations/vector_field.png &quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;and a single pixel intensity value, we should be able to reconstruct the original image by expanding intensity values out from the given pixel, using the gradients. The first image below is an example original, the second, the reconstructed version.&lt;/p&gt;

&lt;figure class=&quot;half&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/toy/toy_problem.png &quot; /&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/toy/reconstructed_toy.png &quot; /&gt;
  &lt;figcaption&gt;sum(|1 - 2|): 0.0305&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I was able to reduce the execution time of this reconstruction significantly (from around 15 seconds to around 4 seconds) by building the sparse constraint matrices via vectorization.&lt;/p&gt;

&lt;h2 id=&quot;poisson-blending&quot;&gt;Poisson Blending&lt;/h2&gt;

&lt;p&gt;
  One way to blend in image into another is with Poisson blending. There are
  two images: a source image, and a target image in which we want to place the
  source image. We create a mask that selects the portion of the source
  we want to blend into the target. Then, we set up the following constraints:
  &lt;ul&gt;
    &lt;li&gt;
      Pixels in the target image that aren&#39;t in the masked area should be close
      to the intensity values in the target.
    &lt;/li&gt;
    &lt;li&gt;
      The gradients of pixels in the masked area should be constrained to have
      close to the gradients of those in the source image.
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/equations/poisson.png &quot; /&gt;
  &lt;figcaption&gt;v = result, t = target, s = source&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here are some results of Poisson blending:&lt;/p&gt;

&lt;h3 id=&quot;dirsky&quot;&gt;Dirsky&lt;/h3&gt;
&lt;figure class=&quot;half&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/dirsky/dirsky.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/dirsky/dirks.jpg &quot; /&gt;
  &lt;figcaption&gt;source&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/dirsky/oski.jpg &quot; /&gt;
  &lt;figcaption&gt;target&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/dirsky/naive_dirsky.jpg &quot; /&gt;
  &lt;figcaption&gt;naive overlay&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;mona-steven&quot;&gt;Mona Steven&lt;/h3&gt;
&lt;figure class=&quot;fourth&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mona_steven/mona_steven.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;figure class=&quot;really-tiny&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mona_steven/steven.jpg &quot; /&gt;
  &lt;figcaption&gt;source&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;really-tiny&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mona_steven/mona.jpg &quot; /&gt;
  &lt;figcaption&gt;target&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;really-tiny&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mona_steven/naive_mona_steven.jpg &quot; /&gt;
  &lt;figcaption&gt;overlay&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;martian&quot;&gt;Martian&lt;/h3&gt;

&lt;figure class=&quot;half&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mars/astronaut_result.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mars/astronaut.jpg &quot; /&gt;
  &lt;figcaption&gt;source&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mars/mars.jpg &quot; /&gt;
  &lt;figcaption&gt;target&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/mars/naive_astronaut.jpg &quot; /&gt;
  &lt;figcaption&gt;overlay&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;Martian&lt;/em&gt; could be considered a failure case. Upon closer inspection, the color palette transferred nicely, but there are weird blur and stretch artifacts surrounding the martian. This is because the background in the source image is not consistent.&lt;/p&gt;

&lt;h2 id=&quot;mixed-gradients&quot;&gt;Mixed Gradients&lt;/h2&gt;

&lt;p&gt;Mixed gradients is just like Poisson blending, except we constrain the gradients of the pixels in the masked area to be the gradient of those in the source image OR target image: whichever has a larger magnitude. Note that this gradient choice is made on a per-gradient basis.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/equations/mixed.png &quot; /&gt;
  &lt;figcaption&gt;d_ij is the value of the gradient from the source or the target image with a larger magnitude&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 class=&quot;display&quot;&gt;
  SF Skyline&lt;span&gt; • Notice that the mixed gradients allow the tall buildings and the bridge to appear in front of the galaxy.&lt;/span&gt;
&lt;/h3&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/skyline2/skyline3.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/skyline2/skyline.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/skyline2/galaxy.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/skyline2/polygon3.png &quot; /&gt;
&lt;/figure&gt;

&lt;h3 class=&quot;display&quot;&gt;
  Banksy on Brick&lt;span&gt; • The colors of the original piece are preserved, but toned to match the bricks. The brick texture also prevails because of its larger gradients.&lt;/span&gt;
&lt;/h3&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/graffiti/graffiti.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/graffiti/bricks.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/graffiti/graffiti.png &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/graffiti/polygon.png &quot; /&gt;
&lt;/figure&gt;

&lt;h3 class=&quot;display&quot;&gt;
  That&#39;s No Moon&lt;span&gt; • The Death Star is faded to more match the brightness and color of the sky. Notice how the clouds float in front of the Death Star. Without mixed gradients, the clouds would simply fade out and become blurry when they got to the masked region.
&lt;/span&gt;&lt;/h3&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/no_moon/no_moon_2_mixed.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/no_moon/campanile.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/no_moon/death_star.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/no_moon/polygon.png &quot; /&gt;
&lt;/figure&gt;

&lt;h3 class=&quot;display&quot;&gt;
  Just Dirksy Things&lt;span&gt; • Writing can be applied over images with mixed gradients. Notice how the pink background is completely disregarded because of its virtually zero gradient, while the words stand out due to the high gradient between the pink and letters.
  &lt;/span&gt;
&lt;/h3&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/girly_things/dirsky_things.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/girly_things/dirks.jpg &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/girly_things/girly_things.png &quot; /&gt;
&lt;/figure&gt;
&lt;figure class=&quot;third&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/girly_things/polygon.png &quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;vs-laplacian-pyramid-blending&quot;&gt;Vs. Laplacian Pyramid Blending&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://docs.opencv.org/3.1.0/dc/dff/tutorial_py_pyramids.html&quot;&gt;Laplacian blending&lt;/a&gt; is another cool way to blend images. Here’s a case when Poisson blending is clearly the way to go:&lt;/p&gt;

&lt;figure class=&quot;full&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/baby/sun_baby.jpg &quot; /&gt;
  &lt;figcaption&gt;Poisson blending&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;half&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/baby/sun_baby_laplacian.jpg &quot; /&gt;
  &lt;figcaption&gt;Laplacian pyramid blending&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;half&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/baby/naive_baby.jpg &quot; /&gt;
  &lt;figcaption&gt;naive overlay&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;half&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/baby/baby.jpg &quot; /&gt;
  &lt;figcaption&gt;source&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class=&quot;half&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/gradient-domain-fusion/baby/sun.jpg &quot; /&gt;
  &lt;figcaption&gt;target&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Poisson blending was much better than Laplacian blending in this case. This is because Poisson blending was able to make the overall color palette of the baby match that of the sun, which is the intended effect. Laplacian blending can’t and doesn’t achieve that effect. Laplacian blending can be better when Poisson blending would cause an unwanted color shift.&lt;/p&gt;

&lt;p&gt;◼&lt;/p&gt;
</description>
        <pubDate>Tue, 11 Oct 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/gradient-domain-fusion/</link>
        <guid isPermaLink="true">http://steven.codes/blog/gradient-domain-fusion/</guid>
        
        <category>hot</category>
        
        <category>published</category>
        
        
      </item>
    
      <item>
        <title>Hello World in HOtMEfSPRIbNG</title>
        <description>&lt;div class=&quot;notice&quot;&gt;
  &lt;a href=&quot;http://xeny.net/Homespring&quot;&gt;Homespring&lt;/a&gt; is an esoteric programming language based on metaphors and trees. Learning this language enough to write two basic programs was a fun challenge. On this page are the two programs and their explanations (within the context of the language)!
&lt;/div&gt;

&lt;h2 id=&quot;program&quot;&gt;Program&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;lol bear the universe hatchery
fear Hello,.   Hydro. Power pump pump pump pump future
       powers World!
 never trust the marshy marshy marshy marshy snowmelt
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;structure&quot;&gt;Structure&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;                                              Hello,
                                             /
                                        fear - hydro power - pump - pump - pump - pump - future
                                       /
lol - bear - the - universe - hatchery - powers - World!
                                               \
                                                 never - trust - the - marshy - marshy - marshy - marshy - snowmelt
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;explanation&quot;&gt;Explanation&lt;/h2&gt;

&lt;p&gt;Salmon begin spawning in the hatchery on the first tick. The first salmon swims toward “Hello,” where it spawns and creates a young salmon named “Hello,”. This salmon makes it back to the hatchery on the tick before the water from the spring named future activates the hydro power, which powers fear. Fear blocks the remaining salmon in the “Hello,” branch, and redirects the stream of hatchery salmon toward “World!”. The young salmon named “Hello,” makes it past the bear to the ocean. The homeless salmon that was with it is eaten by the bear. The first redirected salmon spawns at “World!”, and the young spawn makes it past the bear to the ocean. At this point, the snowmelt is out of the marsh and destroys the universe, terminating the program.&lt;/p&gt;

&lt;h2 id=&quot;challenge-wait-for-two-inputs&quot;&gt;Challenge: Wait for Two Inputs&lt;/h2&gt;

&lt;p&gt;The following is a program I wrote that waits for two lines of input from stdin, then prints out both lines together.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lo, inverse. Lock narrows bird
  hydro. Power insulated evaporates Young. sense powers rapids
   spring
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;structure-1&quot;&gt;Structure&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;                    narrows - bird
                   /
lo, - inverse lock - hydro power - insulated - evaporates - young sense - powers - rapids
                                                         \
                                                          spring
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;explanation-1&quot;&gt;Explanation&lt;/h2&gt;

&lt;p&gt;Lo, stdin waits for input. When the first input is received, creating a mature upstream salmon with its name, the mature salmon reaches a fork, and decides to visit the narrows before attempting the hydro power. The salmon makes it to the bird, where it spawns, creating a young fish, which is immediately eaten by the bird. The mature fish switches to traveling downstream, only to find itself blocked from entering the unpowered inverse lock. At this point, a second line of input may have been received, and a new salmon created. This one, however, reaches the inverse lock and must go to hydro power. This is because it cannot fit through the narrows, where the first salmon is waiting patiently. The second salmon swims through the hydro power, past evaporates, which is currently evaporating all watershed from the appropriately named spring. The salmon continues to rapids, where it spawns. The salmon and its young begin to swim downstream, but the young salmon is delayed one tick by the rapids. The young salmon does reach young sense, though, blocking the electricity from powers. Evaporates stops evaporating the spring water for one tick, long enough for the water to get past it. The water gurgles downstream, ultimately powering hydro power, unlocking the inverse lock with just enough time to let both the 1st and 2nd salmon through. By the time the young salmon from rapids get there, though, it is trapped once again, as it has passed young sense, and powers is once again allowing evaporates to evaporate the spring water, which stops the hydro power from keeping the inverse lock activated. The mature salmon whose names are the two lines from stdin reach the ocean, and print their names to stdout.&lt;/p&gt;

&lt;p&gt;◼&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Jul 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/hello-world-in-HOtMEfSPRIbNG/</link>
        <guid isPermaLink="true">http://steven.codes/blog/hello-world-in-HOtMEfSPRIbNG/</guid>
        
        <category>published</category>
        
        
      </item>
    
      <item>
        <title>Checkaroo</title>
        <description>&lt;h2 id=&quot;download--goto&quot;&gt;Download / GOTO&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/languages/html.png&quot; alt=&quot;html icon&quot; class=&quot;icon match-base-font&quot; /&gt;
 Make an account today at: &lt;a href=&quot;http://checkaroo.herokuapp.com/&quot;&gt;checkaroo.herokuapp.com&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-its-about&quot;&gt;What It’s About&lt;/h2&gt;

&lt;p&gt;Checkaroo solves a problem that we had as TA’s of CS10 at Berkeley. Our lab assistants needed to record their hours without involving the TA and taking up class time, but the hours needed some form of approval. With Checkaroo, lab assistants can check themselves in to their section, but their hours won’t count until their TA approves them at their leisure.&lt;/p&gt;

&lt;p&gt;I wrote the app and a suite of integration tests with Ruby on Rails, jQuery, and Cucumber. I also designed the UI, using elements from &lt;a href=&quot;http://materializecss.com/&quot; target=&quot;_blank&quot;&gt;Materialize&lt;/a&gt;.
&lt;!-- clear_ --&gt;&lt;/p&gt;

&lt;p&gt;The app just finished its beta in two UC Berkeley classes, CS61C and CS10. I’ve been using a feedback-iteration loop to improve the design and function of the application during this time. I plan to use the app to manage lab assistants again in CS10 this fall.&lt;/p&gt;

&lt;p&gt;Here are some sample images taken from the live site: (I’m currently writing this image gallery, by the way. Check it out here: &lt;a href=&quot;https://github.com/straversi/easy-gallery&quot;&gt;easy-gallery&lt;/a&gt;)&lt;/p&gt;

&lt;div class=&quot;image-gallery&quot;&gt;
  &lt;div class=&quot;image-container card&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/checkaroo/assistants.png &quot; class=&quot;image-group-1&quot; data-caption=&quot;The assistants whose hours are being recorded&quot; /&gt;&lt;/div&gt;
  &lt;div class=&quot;image-container card&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/checkaroo/sections.png &quot; class=&quot;image-group-1&quot; data-caption=&quot;The sections that have been created by the TAs&quot; /&gt;&lt;/div&gt;
  &lt;div class=&quot;image-container card&quot;&gt;
  &lt;img src=&quot;/blog/assets/posts/checkaroo/home.png &quot; class=&quot;image-group-1&quot; data-caption=&quot;A sample home page for a TA who has taken action on all of their assistants&#39; checkins.&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
var firstGallery = new Gallery(&quot;image-group-1&quot;, false, &quot;/blog/assets/posts/checkaroo/svg/&quot;);
&lt;/script&gt;

</description>
        <pubDate>Thu, 30 Jun 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/checkaroo/</link>
        <guid isPermaLink="true">http://steven.codes/blog/checkaroo/</guid>
        
        <category>project</category>
        
        
      </item>
    
      <item>
        <title>Typer.js</title>
        <description>&lt;h2 id=&quot;download--goto&quot;&gt;Download / GOTO&lt;/h2&gt;

&lt;p&gt;Get the source and documentation:&lt;br /&gt;
&lt;code&gt;$ git clone https://github.com/straversi/Typer.js.git&lt;/code&gt;&lt;br /&gt;
&lt;img src=&quot;/blog/assets/languages/html.png&quot; alt=&quot;html icon&quot; class=&quot;icon match-base-font&quot; /&gt;
 Or, visit the &lt;a href=&quot;http://steven.codes/typerjs/&quot;&gt;hosted docs&lt;/a&gt;&lt;br /&gt;
&lt;img src=&quot;/blog/assets/languages/github.png&quot; alt=&quot;github icon&quot; class=&quot;icon match-base-font&quot; /&gt;
 &lt;a href=&quot;https://github.com/straversi/Typer.js&quot;&gt;Github page&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-its-about&quot;&gt;What It’s About&lt;/h2&gt;

&lt;p&gt;Typer.js provides an HTML interface for creating a typing effect. For example, enter this in your HTML:&lt;br /&gt;
&lt;code&gt;Fact: &amp;lt;span class=&quot;typer&quot; id=&quot;t1&quot; data-delay=&quot;120&quot; data-words=&quot;bears,beets,battlestar galactica&quot; data-colors=&quot;#cb4b16,#d33682,#6c71c4&quot;&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;cursor&quot; data-owner=&quot;t1&quot;&amp;gt;&amp;lt;/span&amp;gt;&lt;/code&gt;&lt;br /&gt;
and get this on your page:&lt;/p&gt;

&lt;p&gt;Fact: &lt;span class=&quot;typer&quot; id=&quot;t1&quot; data-delay=&quot;120&quot; data-words=&quot;bears,beets,battlestar galactica&quot; data-colors=&quot;#cb4b16,#d33682,#6c71c4&quot;&gt;&lt;/span&gt;&lt;span class=&quot;cursor&quot; data-owner=&quot;t1&quot;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;github-button&quot; href=&quot;https://github.com/straversi&quot; data-style=&quot;mega&quot; data-count-href=&quot;/straversi/followers&quot; data-count-api=&quot;/users/straversi#followers&quot; data-count-aria-label=&quot;# followers on GitHub&quot; aria-label=&quot;Follow @straversi on GitHub&quot;&gt;Follow @straversi&lt;/a&gt;&lt;/p&gt;

&lt;script async=&quot;&quot; defer=&quot;&quot; src=&quot;https://buttons.github.io/buttons.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;/blog/assets/posts/typer.js/typer.js&quot;&gt;&lt;/script&gt;

</description>
        <pubDate>Mon, 20 Jun 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/typer.js/</link>
        <guid isPermaLink="true">http://steven.codes/blog/typer.js/</guid>
        
        <category>project</category>
        
        <category>no_compress</category>
        
        
      </item>
    
      <item>
        <title>Project Template</title>
        <description>&lt;h2 id=&quot;download--goto&quot;&gt;Download / GOTO&lt;/h2&gt;

&lt;p&gt;Cool image. &lt;a href=&quot;http://github.com/straversi&quot;&gt;link to download&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;process&quot;&gt;Process&lt;/h2&gt;

&lt;p&gt;Writing about the process.&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Jun 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/project-template/</link>
        <guid isPermaLink="true">http://steven.codes/blog/project-template/</guid>
        
        <category>project</category>
        
        <category>draft</category>
        
        
      </item>
    
      <item>
        <title>Packd</title>
        <description>&lt;h2 id=&quot;download--goto&quot;&gt;Download / GOTO&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://itunes.apple.com/us/app/packd/id1024333170&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;/blog/assets/app-store-button.svg&quot; alt=&quot;App store button&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;process&quot;&gt;Process&lt;/h2&gt;

&lt;p&gt;Packd is an app + service that tells you how crowded a location is. We currently serve 6 popular UC Berkeley spots, like the Engineering Library.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How does it work?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To start counting, a venue plugs in a Raspberry Pi running Packd software. The Pi counts how many phones are communicating with the local wifi network. We use some math to normalize this number, and get a count +/- 5% of the true total.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For consumers, an App&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To see how busy a public location is, we have an app that displays the live count, along with prediction graphs for each day of the week.&lt;/p&gt;

&lt;p&gt;We’re currently working on a scalable solution that is compatible with rapid expansion of Packd locations.&lt;/p&gt;

&lt;p&gt;I wrote the iOS app with Swift 2. I used storyboarding wherever possible.&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Jun 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/packd/</link>
        <guid isPermaLink="true">http://steven.codes/blog/packd/</guid>
        
        <category>project</category>
        
        
      </item>
    
      <item>
        <title>Neural Net</title>
        <description>&lt;h2 id=&quot;download--goto&quot;&gt;Download / GOTO&lt;/h2&gt;

&lt;p&gt;The Neural Net is not downloadable, as it’s based off of a homework assignment. I expanded on the base assignment to allow for arbitrary numbers of hidden units and layers.&lt;/p&gt;

&lt;h2 id=&quot;process&quot;&gt;Process&lt;/h2&gt;

&lt;p&gt;The assignment was to create a Neural Network from scratch. I chose to implement the net in Python, using the numpy package for matrix manipulations. My net achieved ~98% accuracy on the MNIST dataset, which is composed of images of numbers.&lt;/p&gt;

&lt;p&gt;For the assignment, I derived the backpropagation calculations for a net with layers of size 784 ➡️ 200 ➡️ 10, with &lt;em&gt;tanh&lt;/em&gt;, then &lt;em&gt;sigmoid&lt;/em&gt; as the activation functions.&lt;/p&gt;

&lt;p&gt;To extend the assignment, I derived and implemented a general backpropagation algorithm that works with any specified number of hidden layers and units. I also implemented gradient checking via finite differences to help check the backprop during debugging.&lt;/p&gt;

&lt;p&gt;Here is the &lt;a href=&quot;/blog/hw6.pdf&quot;&gt;hw6 specification&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Jun 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/neural-net/</link>
        <guid isPermaLink="true">http://steven.codes/blog/neural-net/</guid>
        
        <category>project</category>
        
        
      </item>
    
      <item>
        <title>Net.js</title>
        <description>&lt;h2 id=&quot;download--goto&quot;&gt;Download / GOTO&lt;/h2&gt;

&lt;p&gt;Get the source:&lt;br /&gt;
&lt;code&gt;$ git clone https://github.com/straversi/Net.js.git&lt;/code&gt;&lt;br /&gt;
&lt;img src=&quot;/blog/assets/languages/html.png&quot; alt=&quot;html icon&quot; class=&quot;icon match-base-font&quot; /&gt;
 To read more about it, my blog post about it.&lt;br /&gt;
&lt;img src=&quot;/blog/assets/languages/github.png&quot; alt=&quot;github icon&quot; class=&quot;icon match-base-font&quot; /&gt;
 &lt;a href=&quot;https://github.com/straversi/Net.js&quot;&gt;Github page&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;process&quot;&gt;Process&lt;/h2&gt;

&lt;p&gt;Net.js is a fun particle simulation of sorts, in which each particle has an anchor point that it tries to stay close to. The user’s cursor acts as a repelling force on the nodes, and they try to escape it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why is it Interesting?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Instead of a normal particle sim with ticks and momentum, I found a linear transformation that rotationally mirrors point A across point B, forming point C. However, in this transformation, the distance from point A to C is kept nearly constant. Because of the nature of the calculation, updates are only necessary whenever the user’s cursor moves.&lt;/p&gt;

&lt;p&gt;Net.js was conceived and completed over the course of several Electrical Engineering 40: Introduction to Microelectronic Circuits sections.&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Jun 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/net.js/</link>
        <guid isPermaLink="true">http://steven.codes/blog/net.js/</guid>
        
        <category>project</category>
        
        
      </item>
    
      <item>
        <title>Beacon</title>
        <description>&lt;h2 id=&quot;download--goto&quot;&gt;Download / GOTO&lt;/h2&gt;

&lt;p&gt;Link coming soon.&lt;/p&gt;

&lt;h2 id=&quot;process&quot;&gt;Process&lt;/h2&gt;

&lt;p&gt;Also coming soon (sorry).&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Jun 2016 02:47:36 -0700</pubDate>
        <link>http://steven.codes/blog/beacon/</link>
        <guid isPermaLink="true">http://steven.codes/blog/beacon/</guid>
        
        <category>project</category>
        
        
      </item>
    
  </channel>
</rss>
